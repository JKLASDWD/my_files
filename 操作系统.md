### 写在前面

截止到2023.7.29的南京大学jyy的2023操作系统课的笔记，强烈推荐

让我感觉学的数字电路“稍微”有那么一点用的课

很可惜，南大的校内OJ并不对外校开放，实验代码的正确性无从考证（

但还是强烈推荐，jyy讲的的确好

课程主页：https://jyywiki.cn/OS/2023

课程教科书：Operating Systems: Three Easy Pieces

https://pages.cs.wisc.edu/~remzi/OSTEP/

（实在看不下去英文可以去找中文版，虽然翻译不咋地，但还算能看）





以下是正文，包含语序混乱以及各种乱七八糟的注解（

图床是自用的腾讯云COS，还算可以？







操作系统

汇编代码和最小可执行文件

最小可执行？会想到Hello World

```c
#include <stdio.h>
int main(){
	printf("Hello World");
	return 0;
}
```

命令行

```
gcc hello.c
file a.out
./a.out 
-->Hello World
objdump命令进行反汇编
gcc hello.c -static
gcc hello.c -static | less
gcc hello.c -static | wc -l
gcc hello.c -static --verbose
```

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230720184929.png)

编译过程

.c ---> .i         

.i----> .s        

.s---->.o

.o---->.out 

```
gcc hello.c -static -Wl --verbose
```



解决异常退出

-->"syscall"

```
movq $SYS_exit, %rax
movq $1, %rdl
syscall
把控制权完全交给操作系统
操作系统可以改变程序状态甚至终止程序
```

（movq等指令为汇编指令集）

### 汇编代码的状态机模型

​	Everything is a state machine: 计算机 = 数字电路 = 状态机

​	状态 = 内存 MM + 寄存器 RR
​	初始状态 = ABI 规定 (例如有一个合法的 %rsp)
​	状态迁移 = 执行一条指令
​		我们花了一整个《计算机系统基础》解释这件事
​		gdb 同样可以观察状态和执行
操作系统上的程序

所有的指令都只能计算
	deterministic: mov, add, sub, call, ...
	non-deterministic: rdrand, ...
	syscall 把 (M,R)(M,R) 完全交给操作系统

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230720220918.png)

编译器 ---> 取栈顶的pc值，执行对应语句

把高级语言编译成为一个状态机，执行指令序列

### 简单 C 程序的状态机模型 (语义)

对 C 程序做出简化

简化：改写成每条语句至多一次运算/函数调用的形式
真的有这种工具 (C Intermediate Language) 和解释器
状态机定义

状态 = 堆 + 栈
初始状态 = main 的第一条语句
状态迁移 = 执行一条语句中的一小步
(这还只是 “粗浅” 的理解)

Talk is cheap. Show me the code. (Linus Torvalds)
任何真正的理解都应该落到可以执行的代码

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230721002850.png)

:%!xxd

%-->全选  (1,$)

!--->调用第三方命令

xxd-->十六进制格式查看文件

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230721003042.png)

ELF--->可执行文件的文件头



![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230721012511.png)

strace -f gcc hello.c |& vim -





![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230722010844.png)

CPU--->FirmWare（主板）

CPU 经过Reset后，寄存器清空，再reboot，将firmware上的指令加载到内存上，一句句执行，启动操作系统

BIOS 提供机制，将程序员的代码载入内存

Legacy BIOS 把第一个可引导设备的第一个 512 字节加载到物理内存的 7c00 位置
此时处理器处于 16-bit 模式
规定 CS:IP = 0x7c00, (R[CS] << 4) | R[IP] == 0x7c00
可能性1：CS = 0x07c0, IP = 0
可能性2：CS = 0, IP = 0x7c00
其他没有任何约束

55aa 引导分区标记（启动盘）


我们真正关心的概念

1.应用程序 (高级语言状态机)
2.系统调用 (操作系统 API)
3.操作系统内部实现
没有人规定上面三者如何实现

通常的思路：真实的操作系统 + QEMU/NEMU 模拟器
我们的思路
应用程序 = 纯粹计算的 Python 代码 + 系统调用
操作系统 = Python 系统调用实现，有 “假想” 的 I/O 设备
def main():
    sys_write('Hello, OS World')

### 在Python中模拟多线程、多进程操作

yield关键字：return一个值，但是对应的对象并未退出

利用yield实现一个模拟的操作系统

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230722220843.png)

多线程之间的切换？



os-model

```python
#!/usr/bin/env python3

import sys
import random
from pathlib import Path

class OperatingSystem():
    """A minimal executable operating system model."""

    SYSCALLS = ['choose', 'write', 'spawn', 'sched']

    class Thread:
        """A "freezed" thread state."""

        def __init__(self, func, *args):
            self._func = func(*args)
            self.retval = None

        def step(self):
            """Proceed with the thread until its next trap."""
            syscall, args, *_ = self._func.send(self.retval)
            self.retval = None
            return syscall, args

    def __init__(self, src):
        variables = {}
        exec(src, variables)
        self._main = variables['main']

    def run(self):
        threads = [OperatingSystem.Thread(self._main)]
        while threads:  # Any thread lives
            try:
                match (t := threads[0]).step():
                    case 'choose', xs:  # Return a random choice
                        t.retval = random.choice(xs)
                    case 'write', xs:  # Write to debug console
                        print(xs, end='')
                    case 'spawn', (fn, args):  # Spawn a new thread
                        threads += [OperatingSystem.Thread(fn, *args)]
                    case 'sched', _:  # Non-deterministic schedule
                        random.shuffle(threads)
            except StopIteration:  # A thread terminates
                threads.remove(t)
                random.shuffle(threads)  # sys_sched()

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print(f'Usage: {sys.argv[0]} file')
        exit(1)

    src = Path(sys.argv[1]).read_text()
    for syscall in OperatingSystem.SYSCALLS:
        src = src.replace(f'sys_{syscall}',        # sys_write(...)
                          f'yield "{syscall}", ')  #  -> yield 'write', (...)

```



```
mosaic 地址 https://jyywiki.cn/pages/OS/2023/mosaic/mosaic.py
```

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230722230152.png)



最小值，为什么是**2**？

```
应该是有错的，正确的应该需要在heap.x＝tmp语句后加一个sched。
如果没有这个sched，对于当前执行Tsum的generator而言，在当前循环执行第一句tmp＝heap.x时，heap.x的值一定是自己在上个循环刚赋值过的值（因为这两个循环的衔接处没有sched就只能这样执行），而构造最小值的关键，就是要有机会每次读取heap.x的值的时候能够有机会读取别的generator刚赋值过的值，只有这样才可以在当前generator的最后一个循环拿到别的generator刚走完第一个循环时的值，从而构建最小值。
```

### 5. 多处理器编程：从入门到放弃

线程：共享内存的执行流

- 执行流拥有独立的堆栈/寄存器

------

简化的线程 API (thread.h)

- ```
  spawn(fn)
  ```

  - 创建一个入口函数是

    ```
    fn
    ```

    的线程，并立即开始执行

    - `void fn(int tid) { ... }`
    - 参数 `tid` 从 1 开始编号

  - 行为：`sys_spawn(fn, tid)`

- ```
  join()
  ```

  - 等待所有运行线程的返回 (也可以不调用)
  - 行为：`while (done != T) sys_sched()`





多处理器编程：一个 API 搞定

```
#include "thread.h"

void Ta() { while (1) { printf("a"); } }
void Tb() { while (1) { printf("b"); } }

int main() {
  create(Ta);
  create(Tb);
}
```

- 这个程序可以利用系统中的多处理器
  - 操作系统会自动把线程放置在不同的处理器上
  - CPU 使用率超过了 100%

#### 问出更多的问题

`Ta` 和 `Tb` 真的共享内存吗？

- 如何证明/否证这件事？

------

如何证明线程具有独立堆栈 (以及确定堆栈的范围)？

- 输出混乱，应该如何处理？





## 状态机的隐含假设

“世界上只有一个状态机”

- 没有其他任何人能 “干涉” 程序的状态
- 推论：对变量的 load 一定返回本线程最后一次 store 的值
  - 这也是编译优化的基本假设

------

但共享内存推翻了这个假设

```
int Tworker() {
  printf("%d\n", x);  // Global x
  printf("%d\n", x);
}
```

- 其他线程随时可以修改x
  - 导致两次可能读到不同的 `x`

## 例子：求和

分两个线程，计算 1+1+1+...+1+1+1(共计 2n 个 1)

```
#define N 100000000
long sum = 0;

void Tsum() { for (int i = 0; i < N; i++) sum++; }

int main() {
  create(Tsum);
  create(Tsum);
  join();
  printf("sum = %ld\n", sum);
}
```

可能的结果

- 119790390, 99872322 (结果可以比 `N` 还要小), ...
- 直接使用汇编指令也不行

## 放弃 (1)：指令/代码执行原子性假设

> “处理器一次执行一条指令” 的基本假设在今天的计算机系统上不再成立 (我们的模型作出了简化的假设)。

单处理器多线程

- 线程在运行时可能被中断，切换到另一个线程执行

多处理器多线程

- 线程根本就是并行执行的

------

(历史) 1960s，大家争先在共享内存上实现原子性 (互斥)

- 但几乎所有的实现都是错的，直到 [Dekker's Algorithm](https://en.wikipedia.org/wiki/Dekker's_algorithm)，还只能保证两个线程的互斥





## 放弃原子性假设的后果

`printf` 还能在多线程程序里调用吗？

```
void thread1() { while (1) { printf("a"); } }
void thread2() { while (1) { printf("b"); } }
```

我们都知道 printf 是有缓冲区的 (为什么？)

- 如果执行 `buf[pos++] = ch` (`pos` 共享) 不就 💥 了吗？
- printf()在其官方文档中提到了这一点，它是多线程安全的(MT-safe)



## 例子：求和 (再次出现)

分两个线程，计算 1+1+1+\ldots+11+1+1+…+1 (共计 2n2*n* 个 11)

```
#define N 100000000
long sum = 0;

void Tsum() { for (int i = 0; i < N; i++) sum++; }

int main() {
  create(Tsum);
  create(Tsum);
  join();
  printf("sum = %ld\n", sum);
}
```

如果添加编译优化？

- `-O1`: 100000000 
- `-O2`: 200000000 

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230724124153.png)

-O1，两个线程现将sum的值读入到寄存器%rdx中，再将循环后的值赋到sum之中

-O2，直接将循环拆开成为常数

## 放弃 (2)：程序的顺序执行假设

> 编译器对内存访问 “eventually consistent” 的处理导致共享内存作为线程同步工具的失效。

刚才的例子

- `-O1`: `R[eax] = sum; R[eax] += N; sum = R[eax]`
- `-O2`: `sum += N;`
- (你的编译器也许是不同的结果)

另一个例子

```
while (!done);
// would be optimized to
if (!done) while (1);
```

## 保证执行顺序

回忆 “编译正确性”

- C 状态和汇编状态机的 “可观测行为等价”

- 方法 1：插入 “不可优化” 代码

  - ```
    asm volatile ("" ::: "memory");
    ```

    - “Clobbers memory”

- 方法 2：标记变量 load/store 为不可优化

  - 使用 `volatile` 变量

------

```
extern int volatile done;

while (!done) ;
```



## 放弃 (3)：处理器间的可见性

## 例子

```
int x = 0, y = 0;

void T1() {
  x = 1; int t = y; // Store(x); Load(y)
  __sync_synchronize();
  printf("%d", t);
}

void T2() {
  y = 1; int t = x; // Store(y); Load(x)
  __sync_synchronize();
  printf("%d", t);
}
```

遍历模型告诉我们：01, 10, 11

实际结论则是：

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230724140908.png)

问题出在哪？

- 机器永远是对的
- Model checker 的结果和实际的结果不同 → 假设错了

## 现代处理器也是 (动态) 编译器！

错误 (简化) 的假设

- 一个 CPU 执行一条指令到达下一状态

------

实际的实现

- 电路将连续的指令 “编译” 成更小的*μ*ops
  - RF[9] = load(RF[7] + 400)
  - store(RF[12], RF[13])
  - RF[3] = RF[4] + RF[5]

------

在任何时刻，处理器都维护一个 *μ*ops 的 “池子”

- 与编译器一样，做 “顺序执行” 假设：没有其他处理器 “干扰”
- 每一周期执行尽可能多的 μops- 多路发射、乱序执行、按序提交

## 放弃 (3)：多处理器间内存访问的即时可见性

> 满足单处理器 eventual memory consistency 的执行，在多处理器系统上可能无法序列化！

当 x≠y 时，对 x, y 的内存读写可以交换顺序

- 它们甚至可以在同一个周期里完成 (只要 load/store unit 支持)
- 如果写x发生 cache miss，可以让读*y*先执行
  - 满足 “尽可能执行 *μ*op” 的原则，最大化处理器性能

```
     # <-----------+
movl $1, (x)   #   |
movl (y), %eax # --+
```

- 在多处理器上的表现
  - 两个处理器分别看到 y=0 和 x=0



## 宽松内存模型 (Relaxed/Weak Memory Model)

> 宽松内存模型的目的是使单处理器的执行更高效。

x86 已经是市面上能买到的 “最强” 的内存模型了 

- 这也是 Intel 自己给自己加的包袱
- 看看 [ARM/RISC-V](https://research.swtch.com/mem-weak@2x.png) 吧，根本就是个分布式系统

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230724142457.png)

```
									X86架构
								每个线程有独立的存储空间
```

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230724142620.png)



```
								ARM架构
```









## 并发编程：从入门到放弃

人类是 sequential creature

- 编译优化 + weak memory model 导致难以理解的并发执行
- 有多难理解呢？
  - [Verifying sequential consistency 是 NP-完全问题](https://epubs.siam.org/doi/10.1137/S0097539794279614)

------

人类是 (不轻言放弃的) sequential creature

- 有问题，就会试着去解决

- 手段：

  “回退到” 顺序执行

  - 标记若干块代码，使得这些代码一定能按某个顺序执行
  - 例如，我们可以安全地在块里记录执行的顺序

顺序执行——————>

插入 “神秘代码”，使得所有其他 “神秘代码” 都不能并发

- 由 “神秘代码” 领导不会并发的代码 (例如 pure functions) 执行

```
void Tsum() {
  stop_the_world();
  // 临界区 critical section
  sum++;
  resume_the_world();
}
```

并非所有块都需要 “stop_the_world”,否则那就和我们的初衷（利用多个线程加速问题处理）违背了。

需要共享资源的块才需要 stop the world，类似于在访问后将资源锁死，防止其他块访问。



## 失败的尝试

```
int locked = UNLOCK;

void critical_section() {
retry:
  if (locked != UNLOCK) {
    goto retry;
  }
  locked = LOCK;

  // critical section

  locked = UNLOCK;
}
```

和 “山寨支付宝” 完全一样的错误

- 并发程序不能保证 load + store 的原子性

即可能存在两个线程同时执行lock!=UNLOCK语句，一样存在冲突

线程与线程之间互相看不到是否正在执行unlock操作，即原子性无法保证

物理世界中，人去解锁一个门，门无法允许两个人去解锁，因为人很“大”

###  更严肃地尝试：确定假设、设计算法

假设：内存的读/写可以保证顺序、原子完成

- ```
  val = atomic_load(ptr)
  ```

  - 看一眼某个地方的字条 (只能看到瞬间的字)
  - 刚看完就可能被改掉

- ```
  atomic_store(ptr, val)
  ```

  - 对应往某个地方 “贴一张纸条” (必须闭眼盲贴)
  - 贴完一瞬间就可能被别人覆盖

------

对应于 model checker

- 每一行可以执行一次全局变量读或写
- 每个操作执行之后都发生 `sys_sched()`

## 正确性不明的奇怪尝试 (Peterson 算法)

A 和 B 争用厕所的包厢

- 想进入包厢之前，A/B 都首先举起自己的旗子

  - A 往厕所门上贴上 “B 正在使用” 的标签
  - B 往厕所门上贴上 “A 正在使用” 的标签

- 然后，

  如果对方举着旗，且门上的名字是对方

  ，等待

  - 否则可以进入包厢

- 出包厢后，放下自己的旗子 (完全不管门上的标签)



## 习题：证明 Peterson 算法正确，或给出反例

进入临界区的情况

- 如果只有一个人举旗，他就可以直接进入
- 如果两个人同时举旗，由厕所门上的标签决定谁进
  - 手快 🈶️ (被另一个人的标签覆盖)、手慢 🈚

------

一些具体的细节情况

- A 看到 B 没有举旗
  - B 一定不在临界区
  - 或者 B 想进但还没来得及把 “A 正在使用” 贴在门上
- A 看到 B 举旗子
  - A 一定已经把旗子举起来了
  - (*!@^#*&!%^(&^!@%#





## “Push-button” Verification 🎖

> 我们 (在完全不理解算法的前提下) 证明了 Sequential 内存模型下 Peterson's Protocol 的 Safety。它能够实现互斥。

并发编程比大家想象得困难

- 感受一下 [Dekker's Algorithm](https://series1.github.io/blog/dekkers-algorithm/)
- “[Myths about the mutual exclusion problem](https://zoo.cs.yale.edu/classes/cs323/doc/Peterson.pdf)” (IPL, 1981)



## 自动遍历状态空间的乐趣

可以帮助我们快速回答更多问题

- 如果结束后把门上的字条撕掉，算法还正确吗？
  - 在放下旗子之前撕
  - 在放下旗子之后撕
- 如果先贴标签再举旗，算法还正确吗？
- 我们有两个 “查看” 的操作
  - 看对方的旗有没有举起来
  - 看门上的贴纸是不是自己
  - 这两个操作的顺序影响算法的正确性吗？
- 是否存在 “两个人谁都无法进入临界区” (liveness)、“对某一方不公平” (fairness) 等行为？
  - 都转换成图 (状态空间) 上的遍历问题了！



## Model Checker 和自动化

电脑为什么叫 “电脑”

- 就是因为它能替代部分人类的思维活动

------

回忆：每个班上都有一个笔记和草稿纸都工工整整的 Ta

- 老师：布置作业画状态图

  - Ta：认认真真默默画完

    - 工整的笔记可以启发思维
    - 但 scale out 非常困难

  - 我：烦死了！劳资不干了！玩游戏去了！

    - 计算思维

      ：写个程序 (model checker) 来辅助

      - 任何机械的思维活动都可以用计算机替代
      - AI 还可以替代启发式/经验式的决策



## 从模型回到现实……

回到我们的假设 (体现在模型)

- Atomic load & store
  - 读/写单个全局变量是 “原子不可分割” 的
  - 但这个假设在现代多处理器上并不成立
- 所以实际上按照模型直接写 Peterson 算法应该是错的？

------

“实现正确的 Peterson 算法” 是合理需求，它一定能实现

- Compiler barrier/volatile 保证不被优化的前提下

  - 处理器提供特殊指令保证可见性

  - 编译器提供

    ```
    __sync_synchronize()
    ```

    函数

    - x86: `mfence`; ARM: `dmb ish`; RISC-V: `fence rw, rw`
    - 同时含有一个 compiler barrier



如何验证peterson算法的正确性？

回到“山寨支付宝”的尝试，如果你“stop_the_world”的尝试并不完美，会出现多个线程同时进入的情况，就可在这个执行过程中通过计数器来判断是否有这个情况发生，进而判断Peterson算法的正确性

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230724231619.png)





Peterson 算法：C 代码实现演示

- 一些有趣的问题
  - Compiler barrier 能够用吗？
  - 哪些地方的 barrier 是不可少的？
- 测试只能证明 “有问题”，不能证明 “没问题”

------

编译器到底做了什么？

- 推荐：

  godbolt.org

  ，你不用装那些 cross compiler 了

  - 你甚至可以看到 compiler barrier 是如何在优化中传递的
    - 再一次：自动化 & 可视化的意义
  - 不懂可以把代码直接扔给 ChatGPT

```c
#include "thread.h"

#define A 1
#define B 2

#define BARRIER __sync_synchronize()

atomic_int nested;
atomic_long count;

void critical_section() {
  long cnt = atomic_fetch_add(&count, 1);
  int i = atomic_fetch_add(&nested, 1) + 1;
  if (i != 1) {
    printf("%d threads in the critical section @ count=%ld\n", i, cnt);
    assert(0);
  }
  atomic_fetch_add(&nested, -1);
}

int volatile x = 0, y = 0, turn;

void TA() {
  while (1) {
    x = 1;                   BARRIER;
    turn = B;                BARRIER; // <- this is critcal for x86
    while (1) {
      if (!y) break;         BARRIER;
      if (turn != B) break;  BARRIER;
    }
    critical_section();
    x = 0;                   BARRIER;
  }
}

void TB() {
  while (1) {
    y = 1;                   BARRIER;
    turn = A;                BARRIER;
    while (1) {
      if (!x) break;         BARRIER;
      if (turn != A) break;  BARRIER;
    }
    critical_section();
    y = 0;                   BARRIER;
  }
}

int main() {
  create(TA);
  create(TB);
}
```

__sync_synchronize();

https://godbolt.org/



```
foo():
        push    rbp
        mov     rbp, rsp
        lock or QWORD PTR [rsp], 0
        nop
        pop     rbp
        ret
```



Peterson算法的实现原理： 内存的读\写是原子不可分割的，但在现代多处理结构上并不成立



原子指令：

普通的变量读写在编译器+处理器的双重优化下行为变得复杂

在计算机世界的多线程处理中，变量读写随时有可能会被打断，而非物理世界的一致与连贯（单线程）。

解决方法：编译器和硬件共同提供不可优化、不可打断的指令

- “原子指令” + compiler barrier



## 实现正确的求和

```
for (int i = 0; i < N; i++)
  asm volatile("lock incq %0" : "+m"(sum));
```

“Bus lock”——从 80386 开始引入 (bus control signal)

”总线锁“

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230724235431.png)

原子指令：将世界分割成停止与不停止的两部分，停止的时间只有他能访问这一块内存

```c
#include "thread.h"

#define N 100000000

long sum = 0;

void atomic_inc(long *ptr) {
  asm volatile(
    "lock incq %0"  // Atomic + memory fence
    : "+m"(*ptr)
    :
    : "memory"
  );
}

void Tsum() {
  for (int i = 0; i < N; i++) {
    atomic_inc(&sum);
  }
}

int main() {
  create(Tsum);
  create(Tsum);
  join();
  printf("sum = %ld\n", sum);
}
```







## 互斥问题：定义

互斥 (mutual exclusion)，“互相排斥”

- 实现 `lock_t` 数据结构和 `lock/unlock` API:

```C
typedef struct {
  //...
} lock_t;
void lock(lock_t *lk);
void unlock(lock_t *lk);
```

------

一把 “排他性” 的锁——对于锁对象 `lk`

- 如果某个线程持有锁，则其他线程的 `lock` 不能返回 (Safety)
- 在多个线程执行 `lock` 时，至少有一个可以返回 (Liveness)
- 能正确处理处理器乱序、宽松内存模型和编译优化



## 互斥问题的经典算法

Peterson 算法

- 包间、旗子和门上的字条
- 假设 atomic load/store
  - 实现这个假设也不是非常容易的 ([peterson.c](https://jyywiki.cn/pages/OS/2023/c/peterson.c))

------

因此，假设很重要

- 不能同时读/写共享内存 (1960s) 不是一个好的假设
  - Load (环顾四周) 的时候不能写，“看一眼就把眼睛闭上”
  - Store (改变物理世界状态) 的时候不能读，“闭着眼睛动手”
  - 这是《操作系统》课
    - 更喜欢直观、简单、粗暴 (稳定)、有效的解决方法





## 实现互斥的基本假设

允许使用使我们可以不管一切麻烦事的原子指令

```C
void atomic_inc(long *ptr);
int atomic_xchg(int val, int *ptr);
```

------

看起来是一个普通的函数，但假设：

- 包含一个原子指令
  - 指令的执行不能被打断
- 包含一个 compiler barrier
  - 无论何种优化都不可越过此函数
- 包含一个 memory fence
  - 保证处理器在 stop-the-world 前所有对内存的 store 都 “生效”
  - 即对 resume-the-world 之后的 load 可见



## Atomic Exchange 实现

```C
int xchg(int volatile *ptr, int newval) {
  int result;
  asm volatile(
    // 指令自带 memory barrier
    "lock xchgl %0, %1"
    : "+m"(*ptr), "=a"(result)
    : "1"(newval)
    // Compiler barrier
    : "memory"
  );
  return result;
}
```

//不用太在意这个实现，实在是好难懂...

memory-> compile barrier

lock       -> memory barrier

//OSTEP上的C伪代码

```C
 int TestAndSet(int *old_ptr, int new) {
 int old = *old_ptr; // fetch old value at old_ptr
 *old_ptr = new; // store 'new' into old_ptr
 return old; // return the old value
 }
```

获取值，存储，返回旧值

```C
//比较显而易见的实现自旋锁锁的lock和unlock函数
void lock(lock_t *lock) {
 while (TestAndSet(&lock->flag, 1) == 1)
 ; // spin-wait (do nothing)
 }
 void unlock(lock_t *lock) {
 lock->flag = 0;
 }
```

```C
//首先假设一个线程在运行，调用lock()，没有其他线程持有锁，所以flag 是0。当调用TestAndSet(flag, 1)方法，返回0，线程会跳出while循环，获取锁。同时也会原子的设置flag 为1，标志锁已经被持有。当线程离开临界区，调用unlock()将flag 清理为0。

//第二种场景是，当某一个线程已经持有锁（即flag 为1）。本线程调用lock()，然后调用TestAndSet(flag, 1)，这一次返回1。只要另一个线程一直持有锁，TestAndSet()会重复返回1，本线程会一直自旋。当flag 终于被改为0，本线程会调用TestAndSet()，返回0 并且原子地设置为1，从而获得锁，进入临界区。
```



## 实现互斥：做题家 v.s. 科学家

```
void lock(lock_t *lk);
void unlock(lock_t *lk);
```

做题家：拿到题就开始排列组合

- 熟练得让人心疼
  - 如果长久的训练都是 “必须在规定的时间内正确解出问题”，那么浪费时间的思考自然就少了

------

科学家：考虑更多更根本的问题

- 我们可以设计出怎样的原子指令？
  - 它们的表达能力如何？
- 计算机硬件可以提供比 “一次 load/store” 更强的原子性吗？
  - 如果硬件很困难，软件/编译器可以么？





## 实现互斥：自旋锁

```
int table = YES;

void lock() {
retry:
  int got = xchg(&table, NOPE);
  if (got == NOPE)
    goto retry;
  assert(got == YES);
}

void unlock() {
  xchg(&table, YES);  // 为什么不是 table = YES; ?
}
```

(在 model checker 中检查)



1、若在lock和unlock的过程中，线程crash了，那么YES就永远消失了，线程就发生了死锁

trick：c++的析构函数可以做到构造时上锁，退出时去锁，能够一定程度上避免在lock和unlock时不甚写了return语句造成线程死锁（return时线程结束，自动调用析构函数）

2、table = YES？ 为了防止自动优化和某些奇怪的“bug”，最保险以及最安全的方法还是调用unlock语句



## 实现互斥：自旋锁

在 xchg 的假设下简化实现

- 包含一个原子指令
- 包含一个 compiler barrier
- 包含一个 memory fence
  - sum-spinlock demo

```
int locked = 0;

void lock() {
  while (xchg(&locked, 1));
}

void unlock() {
  xchg(&locked, 0);
}
```



回到累加

```
#include "thread.h"

#define N 100000000
#define M 10

long sum = 0;

int xchg(int volatile *ptr, int newval) {
  int result;
  asm volatile(
    "lock xchgl %0, %1"
    : "+m"(*ptr), "=a"(result)
    : "1"(newval)
    : "memory"
  );
  return result;
}

int locked = 0;

void lock() {
  while (xchg(&locked, 1)) ;
}

void unlock() {
  xchg(&locked, 0);
}

void Tsum() {
  long nround = N / M;
  for (int i = 0; i < nround; i++) {
    lock();
    for (int j = 0; j < M; j++) {
      sum++;  // Non-atomic; can optimize
    }
    unlock();
  }
}

int main() {
  assert(N % M == 0);
  create(Tsum);
  create(Tsum);
  join();
  printf("sum = %ld\n", sum);
}
```



## 更强大的原子指令

Compare and exchange (“test and set”)

- (lock) cmpxchg SRC, DEST

```
TEMP = DEST
if accumulator == TEMP:
    ZF = 1
    DEST = SRC
else:
    ZF = 0
    accumulator = TEMP
```

- 🤔 看起来没复杂多少，好像又复杂了很多
  - 学编程/操作系统 “纸面理解” 是不行的
  - 一定要写代码加深印象
    - 对于这个例子：我们可以列出 “真值表

//OSTEP C的伪代码

```c
 int CompareAndSwap(int *ptr, int expected, int new) {
 int actual = *ptr;
 if (actual == expected)
 *ptr = new;
 return actual;
 }
// *注意，称为伪代码的意思是它并不能实现真正的硬件效果，因为每一步在实际执行时并非原子指令
// 在真正使用cmpxchg时，每一步都是原子指令，即使用lock和memory保证compiler和memory barrier
 
```

```C
 void lock(lock_t *lock) {
 while (CompareAndSwap(&lock->flag, 0, 1) == 1)
 ; // spin
 }
//lock函数
```

比起xchg，cmpxchg少了一次store，多了一次判断



## 多出的 Compare: 用处

同时检查上一次获得的值是否仍然有效 + 修改生效

```
// Create a new node
retry:
  expected = head;
  node->next = expected;
  seen = cmpxchg(expected, node, &head);
  if (seen != expected)
    goto retry;
```





## 自旋锁的缺陷

性能问题 (1)

- 除了进入临界区的线程，其他处理器上的线程都在空转
- 争抢锁的处理器越多，利用率越低
  - 4 个 CPU 运行 4 个 sum-spinlock 和 1 个 OBS
    - 任意时刻都只有一个 sum-atomic 在有效计算
  - 均分 CPU, OBS 就分不到 100% 的 CPU 了

------

性能问题 (2)

- 持有自旋锁的线程

  可能被操作系统切换出去

  - 操作系统不 “感知” 线程在做什么
  - (但为什么不能呢？)

- 实现 100% 的资源浪费



## Scalability: 性能的新维度

> 同一份计算任务，时间 (CPU cycles) 和空间 (mapped memory) 会随处理器数量的增长而变化。

用自旋锁实现 sum++ 的性能问题

- 严谨的统计很难
  - CPU 动态功耗
  - 系统中的其他进程
  - 超线程
  - NUMA
  - ……
  - [Benchmarking crimes](https://www.cse.unsw.edu.au/~gernot/benchmarking-crimes.html)

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230726225413.png)



sum-scalability

```
#include "thread.h"
#include "thread-sync.h"

#define N 10000000
spinlock_t lock = SPIN_INIT();

long n, sum = 0;

void Tsum() {
  for (int i = 0; i < n; i++) {
    spin_lock(&lock);
    sum++;
    spin_unlock(&lock);
  }
}

int main(int argc, char *argv[]) {
  assert(argc == 2);
  int nthread = atoi(argv[1]);
  n = N / nthread;
  for (int i = 0; i < nthread; i++) {
    create(Tsum);
  }
  join();
  assert(sum == n * nthread);
}
```



thread-sync.h

```
#include <semaphore.h>

// Spinlock
typedef int spinlock_t;
#define SPIN_INIT() 0

static inline int atomic_xchg(volatile int *addr, int newval) {
  int result;
  asm volatile ("lock xchg %0, %1":
    "+m"(*addr), "=a"(result) : "1"(newval) : "memory");
  return result;
}

void spin_lock(spinlock_t *lk) {
  while (1) {
    intptr_t value = atomic_xchg(lk, 1);
    if (value == 0) {
      break;
    }
  }
}
void spin_unlock(spinlock_t *lk) {
  atomic_xchg(lk, 0);
}

// Mutex
typedef pthread_mutex_t mutex_t;
#define MUTEX_INIT() PTHREAD_MUTEX_INITIALIZER
void mutex_lock(mutex_t *lk)   { pthread_mutex_lock(lk); }
void mutex_unlock(mutex_t *lk) { pthread_mutex_unlock(lk); }

// Conditional Variable
typedef pthread_cond_t cond_t;
#define COND_INIT() PTHREAD_COND_INITIALIZER
#define cond_wait pthread_cond_wait
#define cond_broadcast pthread_cond_broadcast
#define cond_signal pthread_cond_signal

// Semaphore
#define P sem_wait
#define V sem_post
#define SEM_INIT(sem, val) sem_init(sem, 0, val)
```

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230726225641.png)



## 自旋锁的使用场景

1. 临界区几乎不 “拥堵”
2. 持有自旋锁时禁止执行流切换



------

使用场景：操作系统内核的并发数据结构 (短临界区)

- 操作系统可以关闭中断和抢占
  - 保证锁的持有者在很短的时间内可以释放锁
- (如果是虚拟机呢...😂)
  - PAUSE 指令会触发 VM Exit
- 但依旧很难做好
  - [An analysis of Linux scalability to many cores](https://www.usenix.org/conference/osdi10/analysis-linux-scalability-many-cores) (OSDI'10)





## 实现线程 + 长临界区的互斥

> 作业那么多，与其干等 Online Judge 发布，不如把自己 (CPU) 让给其他作业 (线程) 执行？

“让” 不是 C 语言代码可以做到的 (C 代码只能执行指令)

- 但有一种特殊的指令：syscall

- 把锁的实现放到操作系统里就好啦

  - ```
    syscall(SYSCALL_lock, &lk);
    ```

    - 试图获得 `lk`，但如果失败，就切换到其他线程

  - ```
    syscall(SYSCALL_unlock, &lk);
    ```

    - 释放 `lk`，如果有等待锁的线程就唤醒





得不到锁时，不浪费CPU



## 实现线程 + 长临界区的互斥 (cont'd)

操作系统 = 更衣室管理员

- 先到的人 (线程)
  - 成功获得手环，进入游泳馆
  - `*lk = 🔒`，系统调用直接返回
- 后到的人 (线程)
  - 不能进入游泳馆，排队等待
  - 线程放入等待队列，执行线程切换 (yield)
- 洗完澡出来的人 (线程)
  - 交还手环给管理员；管理员把手环再交给排队的人
  - 如果等待队列不空，从等待队列中取出一个线程允许执行
  - 如果等待队列为空，`*lk = ✅`
- 管理员 (OS) 使用自旋锁确保自己处理手环的过程是原子的



## 关于互斥的一些分析

自旋锁 (线程直接共享 locked)

- 更快的 fast path
  - xchg 成功 → 立即进入临界区，开销很小
- 更慢的 slow path
  - xchg 失败 → 浪费 CPU 自旋等待

------

互斥锁 (通过系统调用访问 locked)

- 更经济的 slow path
  - 上锁失败线程不再占用 CPU
- 更慢的 fast path
  - 即便上锁成功也需要进出内核 (syscall)

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230726235931.png)





## 开始调试之前

摆正心态 (编程哲 ♂ 学)





机器永远是对的

> 不管是 crash 了，Wrong Answer 了，还是虚拟机神秘重启，都是自己背锅





未测代码永远是错的

> 你以为最不可能出 bug 的地方，往往 bug 就在那躺着



“软件” 的两层含义

- 人类需求在信息世界的投影
  - 理解错需求 → bug
- 计算过程的精确 (数学) 描述
  - 实现错误 → bug

------

调试 (debugging)

- 已知程序有 bug，如何找到？





## 调试困难的根本原因

因为 bug 的触发经历了漫长的过程

- 需求 → 设计 → 代码 (状态机) → Fault (bug) → Error (程序状态错) → Failure
  - 我们只能观测到 failure (可观测的结果错)
  - 我们可以检查状态的正确性 (但非常费时)
  - 无法预知 bug 在哪里 (每一行 “看起来” 都挺对的)



## 调试理论

> 调试理论：如果我们能判定任意程序状态的正确性，那么给定一个 failure，我们可以通过二分查找定位到第一个 error 的状态，此时的代码就是 fault (bug)。

------

调试理论：推论

- 为什么我们喜欢 “单步调试”？
  - 从一个假定正确的状态出发
  - 每个语句的行为有限，容易判定是否是 error
- 为什么调试理论看起来很没用？
  - 因为判定程序状态的正确性非常困难
    - (是否在调试 DP 题/图论算法时陷入时间黑洞？)

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230728004530.png)



## 调试理论 (cont'd)

实际中的调试：观察状态机执行 (trace) 的某个侧面

- 缩小错误状态 (error) 可能产生的位置
- 作出适当的假设
- 再进行细粒度的定位和诊断

------

最重要的两个工具

- printf → 自定义 log 的 trace
  - 灵活可控、能快速定位问题大概位置、适用于大型软件
  - 无法精确定位、大量的 logs 管理起来比较麻烦
- gdb → 指令/语句级 trace
  - 精确、指令级定位、任意查看程序内部状态
  - 耗费大量时间



## 你们是否遇到过以下令人抓狂的情况？

```
bash: curl: command not found
```

------

```
fatal error: 'sys/cdefs.h': No such file or directory
#include <sys/cdefs.h>
```

------

```
make[2]: *** run: No such file or directory.  Stop.
Makefile:31: recipe for target 'run' failed
make[1]: *** [run] Error 2
...
```





## 计算机世界：一切皆可调试

程序 = 计算机系统 = 状态机

- 机器永远是对的

- UNIX 世界里你做任何事情都是在

  编程

  - 因此配置错、make 错等，都是程序或输入/配置有 bug
  - (输入/配置可以看成是程序的一部分)

------

所有问题都可以用调试理论解决

- 你写了一个程序，现在这个程序出 bug 了 (例如 Segmentation Fault)，你是怎样排查这个问题的？
  - curl: command not found
  - `'sys/cdefs.h'`: No such file or directory
  - make: run: No such file or directory





## 使用调试理论

Debug (fault localization) 的基本理论回顾：

- Fault (程序/输入/配置错) → Error → Failure (可观测)
  - 绝大部分工具的 Failure 都有 “原因报告”
    - 因此能帮助你快速定位 fault
  - `man perror`：标准库有打印 error message 的函数

------

如果问题不能帮你定位到 fault/error？

- 出错原因报告不准确或不够详细
- 程序执行的过程不够详细
  - 既然我们有需求，那别人肯定也会有这个需求
    - 一定有信息能帮助我们！



UNIX--> 标准输出和标准错误输出





## GDB: 入门

GDB: 最常用的命令在 [gdb cheat sheet](https://jyywiki.cn/pages/OS/manuals/gdb-cheat-sheet.pdf)

- 打印贴在电脑前，调试时候看一遍，很快就大致记住了

------

想要更好的体验？

- GDB 本身也是一个编程语言
  - 它甚至支持 Python
  - 我们可以执行一些初始化代码 (-x)
- 库函数也是代码
  - directory 命令增加源码路径
- GDB 有许多前端
  - cgdb, pwndbg, vscode, ...
- [RTFM](https://sourceware.org/gdb/current/onlinedocs/gdb.html/) - M 比 ChatGPT 好用在于它不需要 prompt 且全面



> printf 是我们最早接触的库函数之一。那么在 glibc 中的 printf 代码到底做了什么呢？在这个例子中，我们会发现 “production” 的代码经过多年的积累演化，已经非常复杂。因此我们的学习路径是让大家实现简化的版本 (klib)，并且鼓励大家阅读一些更轻量级的 libc 代码 (例如 [musl](https://musl.libc.org/), newlib 等)。很多开源操作系统都选择了 musl 作为应用程序的支撑平台：它功能全面、精巧，且[移植](https://musl.libc.org/doc/1.1.24/manual.html)它的困难比 glibc 小得多



gcc -ggdb -Wall .c

gdb .o

layout src

record full

si，rsi

info thread

thread







## 调试理论：应用 (Again)



需求 → 设计 → 代码 → Fault → Error → Failure

------

“Technical Debt”

> 每当你写出不好维护的代码，你都在给你未来的调试/需求变更挖坑。

------

中枪了？

- 为了快点跑程序，随便写的 klib
- 为了赶紧实现指令，随手写的代码
- 为了应付老板，随便写的系统实现
  - jyy 的 code review: ~~日常血压升高时间~~





## 编程基本准则：回顾

> Programs are meant to be read by humans (AIs) and only incidentally for computers to execute. — *D. E. Knuth*
>
> (程序首先是拿给人读的，其次才是被机器执行。)

好的程序

- 不言自明：能知道是做什么的 (specification)
  - 因此代码风格很重要

------

- 不言自证：能确认代码和 specification 一致
  - 因此代码中的逻辑流很重要

------

- 人类新纪元的评判标准
  - AI 是否能正确理解/维护你的代码





## 调试理论的最重要应用

> 写好读、易验证的代码
>
> 在代码中添加更多的断言 (assertions)

------

断言的意义

- 把代码中隐藏的 specification 写出来
  - Fault → Error (靠测试)
  - Error → Failure (靠断言)
    - Error 暴露的越晚，越难调试
    - 追溯导致 assert failure 的变量值 (slice) 通常可以快速定位到 bug



## 例子：维护父亲节点的平衡树

![img](http://web.cecs.pdx.edu/~sheard/course/Cs163/Graphics/rotation.png)

```
// 结构约束
assert(u->parent == u ||
       u->parent->left  == u ||
       u->parent->right == u);
assert(!u->left  || u->left->parent  == u);
assert(!u->right || u->right->parent == u);

// 数值约束
assert(!u->left  || u->left->val  < u->val);
assert(!u->right || u->right->val > u->val);
```





![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230728005232.png)





## 福利：更多的断言

你是否希望在每一次指针访问时，都增加一个断言

- `assert(obj->low <= ptr && ptr < obj->high);`

```
int *ref(int *a, int i) {
  return &a[i];
}

void foo() {
  int arr[64];
  *ref(arr, 64) = 1; // bug
}
```

------

一个神奇的编译选项

- ```
  -fsanitize=address
  ```

  - Address Sanitizer; asan “动态程序分析”



## 同步 (Synchronization)

两个或两个以上随时间变化的量在变化过程中保持一定的相对关系

- 同步电路 (一个时钟控制所有触发器)
- iPhone/iCloud 同步 (手机 vs 电脑 vs 云端)
- 变速箱同步器 (合并快慢速齿轮)
- 同步电机 (转子与磁场转速一致)
- 同步电路 (所有触发器在边沿同时触发)

------

异步 (Asynchronous) = 不需要同步

- 上述很多例子都有异步版本 (异步电机、异步电路、异步线程)





## 并发程序中的同步

并发程序的步调很难保持 “完全一致”

- 线程同步：在某个时间点共同达到互相已知的状态



再次把线程想象成我们自己

- NPY：等我洗个头就出门/等我打完这局游戏就来
- 舍友：等我修好这个 bug 就吃饭
- 导师：等我出差回来就讨论这个课题
- jyy:等我成为卷王就躺平
  - “先到先等”，在条件达成的瞬间再次恢复并行
  - 同时开始出去玩/吃饭/讨论





## 生产者-消费者问题：学废你就赢了

> 99% 的实际并发问题都可以用生产者-消费者解决。

```
void Tproduce() { while (1) printf("("); }
void Tconsume() { while (1) printf(")"); }
```

在 `printf` 前后增加代码，使得打印的括号序列满足

- 一定是某个合法括号序列的前缀
- 括号嵌套的深度不超过*n*
  - *n*=3, `((())())(((` 合法
  - *n*=3, `(((())))`, `(()))` 不合法
- 生产者-消费者问题中的同步
  - Tproduce: 等到有空位时才能打印左括号
  - Tconsume: 等到有多余的左括号时才能打印右括号



## 计算图、调度器和生产者-消费者问题

为什么叫 “生产者-消费者” 而不是 “括号问题”？

- 左括号：生产资源 (任务)、放入队列
- 右括号：从队列取出资源 (任务) 执行

------

并行计算基础：计算图

- 计算任务构成有向无环图
  - (*u*,*v*)∈*E* 表示 *v* 要用到前 *u* 的值
- 只要调度器 (生产者) 分配任务效率够高，算法就能并行
  - 生产者把任务放入队列中
  - 消费者 (workers) 从队列中取出任务





## 生产者-消费者：实现

能否用互斥锁实现括号问题？

- 左括号：嵌套深度 (队列) 不足 �*n* 时才能打印

- 右括号：嵌套深度 (队列)>1时才能打印

  - 当然是等到满足条件时再打印了

     (代码演示)

    - 用互斥锁保持条件成立



- 压力测试 + 观察输出结果
- 自动观察输出结果：[pc-check.py](https://jyywiki.cn/pages/OS/2023/c/pc-check.py)
- 未来：copilot 观察输出结果，并给出修复建议
- 更远的未来：~~我们都不需要不存在了~~





## 同步问题：分析

> 线程同步由条件不成立等待和同步条件达成继续构成

线程 join

- Tmain 同步条件：`nexit == T`
- Tmain 达成同步：最后一个线程退出 `nexit++`

------

生产者/消费者问题

- Tproduce 同步条件：`CAN_PRODUCE (count < n)`
- Tproduce 达成同步：Tconsume `count--`
- Tconsume 同步条件：`CAN_CONSUME (count > 0)`
- Tconsume 达成同步：Tproduce `count++`



## 理想中的同步 API

```
wait_until(CAN_PRODUCE) {
  count++;
  printf("(");
}

wait_until(CAN_CONSUME) {
  count--;
  printf(")");
}
```

若干实现上的难题

- 正确性
  - 大括号内代码执行时，其他线程不得破坏等待的条件
- 性能
  - 不能 spin check 条件达成
  - 已经在等待的线程怎么知道条件被满足？





## 条件变量：理想与实现之间的折衷

一把互斥锁 + 一个 “条件变量” + 手工唤醒

- wait(cv, mutex) 💤
  - 调用时必须保证已经获得 mutex
  - wait 释放 mutex、进入睡眠状态
  - 被唤醒后需要重新执行 lock(mutex)
- signal/notify(cv) 💬
  - 随机私信一个等待者：醒醒
  - 如果有线程正在等待 cv，则唤醒其中一个线程
- broadcast/notifyAll(cv) 📣
  - 叫醒所有人
  - 唤醒全部正在等待 cv 的线程





## 条件变量：实现生产者-消费者

```
void Tproduce() {
  mutex_lock(&lk);
  if (!CAN_PRODUCE) cond_wait(&cv, &lk);
  printf("("); count++; cond_signal(&cv);
  mutex_unlock(&lk);
}

void Tconsume() {
  mutex_lock(&lk);
  if (!CAN_CONSUME) cond_wait(&cv, &lk);
  printf(")"); count--; cond_signal(&cv);
  mutex_unlock(&lk);
}
```

代码演示 & 压力测试 & 模型检验

- (Small scope hypothesis)



producer和consumer一多，测试就不通过，为什么？

唤醒的时候没有重新检查条件变量，而是直接打印括号





正确样例



```C
#include "thread.h"
#include "thread-sync.h"

int n, count = 0;
mutex_t lk = MUTEX_INIT();
cond_t cv = COND_INIT();
 
#define CAN_PRODUCE (count < n)
#define CAN_CONSUME (count > 0)

void Tproduce() {
  while (1) {
    mutex_lock(&lk);
    while (!CAN_PRODUCE) {
      cond_wait(&cv, &lk);
    }
    printf("("); count++;
    cond_broadcast(&cv);
    mutex_unlock(&lk);
  }
}

void Tconsume() {
  while (1) {
    mutex_lock(&lk);
    while (!CAN_CONSUME) {
      cond_wait(&cv, &lk);
    }
    printf(")"); count--;
    cond_broadcast(&cv);
    mutex_unlock(&lk);
  }
}


int main(int argc, char *argv[]) {
  assert(argc == 3);
  n = atoi(argv[1]);
  int T = atoi(argv[2]);
  setbuf(stdout, NULL);
  for (int i = 0; i < T; i++) {
    create(Tproduce);
    create(Tconsume);
  }
}
```



> 编写正确的并发程序并非易事，即便是资深的系统程序员 (包括 Linux 内核开发者) 都无法避免在代码中引入并发 bug。压力测试、模型检验都是帮助我们提升对并发程序正确性信心的手段。除此之外，防御性地编程 (例如写出尽可能简单、正确性明了的代码) 也是至关重要的。



## 条件变量：万能并行计算框架 (M2)

```
struct work {
  void (*run)(void *arg);
  void *arg;
}

void Tworker() {
  while (1) {
    struct work *work;
    wait_until(has_new_work() || all_done) {
      work = get_work();
    }
    if (!work) break;
    else {
      work->run(work->arg); // 允许生成新的 work (注意互斥)
      release(work);  // 注意回收 work 分配的资源
    }
  }
}
```





## 条件变量：更古怪的习题/面试题

有三种线程

- Ta 若干: 死循环打印 `<`
- Tb 若干: 死循环打印 `>`
- Tc 若干: 死循环打印 `_`

任务：

- 对这些线程进行同步，使得屏幕打印出 `<><_` 和 `><>_` 的组合

------

使用条件变量，只要回答三个问题：

- 打印 “`<`” 的条件？
- 打印 “`>`” 的条件？
- 打印 “`_`” 的条件？





源码

```
#include "thread.h"
#include "thread-sync.h"

#define LENGTH(arr) (sizeof(arr) / sizeof(arr[0]))

enum { A = 1, B, C, D, E, F, };

struct rule {
  int from, ch, to;
} rules[] = {
  { A, '<', B },
  { B, '>', C },
  { C, '<', D },
  { A, '>', E },
  { E, '<', F },
  { F, '>', D },
  { D, '_', A },
};
int current = A, quota = 1;

mutex_t lk = MUTEX_INIT();
cond_t cv = COND_INIT();

int next(char ch) {
  for (int i = 0; i < LENGTH(rules); i++) {
    struct rule *rule = &rules[i];
    if (rule->from == current && rule->ch == ch) {
      return rule->to;
    }
  }
  return 0;
}

static int can_print(char ch) {
    return next(ch) != 0 && quota > 0;
}

void fish_before(char ch) {
  mutex_lock(&lk);
  while (!can_print(ch)) {
    // can proceed only if (next(ch) && quota)
    cond_wait(&cv, &lk);
  }
  quota--;
  mutex_unlock(&lk);
}

void fish_after(char ch) {
  mutex_lock(&lk);
  quota++;
  current = next(ch);
  assert(current);
  cond_broadcast(&cv);
  mutex_unlock(&lk);
}

const char roles[] = ".<<<<<>>>>___";

void fish_thread(int id) {
  char role = roles[id];
  while (1) {
    fish_before(role);
    putchar(role);  // Not lock-protected
    fish_after(role);
  }
}

int main() {
  setbuf(stdout, NULL);
  for (int i = 0; i < strlen(roles); i++)
    create(fish_thread);
}
```



同步的本质是线程需要等待某件它所预期的事件发生，而事件的发生总是可以用共享状态的条件来表达。并且在这个条件被满足的前提下完成一些动作：

```
WAIT_UNTIL(cond) with (mutex) {
  // cond 在此时成立
  work();
}
```

计算机系统的设计者提供了条件变量的机制模仿这个过程，它与互斥锁联合使用：

- `cond_wait(cv, lk)` 释放互斥锁 `lk` 并进入睡眠状态。注意被唤醒时，`cond_wait` 会重新试图获得互斥，直到获得互斥锁后才能返回。
- `cond_signal(cv)` 唤醒一个在 `cv` 上等待的线程
- `cond_broadcast(cv)` 唤醒所有在 `cv` 上等待的线程

我们也很自然地可以用 wait + broadcast 实现 `WAIT_UNTIL`，从而实现线程之间的同步。







## 复习：生产者-消费者、互斥、条件变量

打印 “合法” 的括号序列 `(())()`

- 左括号对应 push
- 右括号对应 pop

```
#define CAN_PRODUCE (count < n)
#define CAN_CONSUME (count > 0)

wait_until(CAN_PRODUCE) with (mutex) {
  count++;
  printf("(");
}

wait_until(CAN_CONSUME) with (mutex) {
  count--;
  printf(")");
}
```









## 信号量：一种条件变量的特例

```
void P(sem_t *sem) { // wait
  wait_until(sem->count > 0) {
    sem->count--;
  }
}

void V(sem_t *sem) { // post (signal)
  atomic {
    sem->count++;
  }
}
```

------

正是因为条件的特殊性，信号量不需要 broadcast

- P 失败时立即睡眠等待
- 执行 V 时，唤醒任意等待的线程



符合条件直接随机唤醒，多像一个事件监听啊（







## 理解信号量 (1)

初始时 count = 1 的特殊情况

- 互斥锁是信号量的特例

------

```
#define YES 1
#define NO 0

void lock() {
  wait_until(count == YES) {
    count = NO;
  }
}

void unlock() {
  count = YES;
}
```





## 理解信号量 (2)

P - prolaag (try + decrease/down/wait/acquire)

- 试着从袋子里取一个球
  - 如果拿到了，离开
  - 如果袋子空了，排队等待

------

V - verhoog (increase/up/post/signal/release)

- 往袋子里放一个球
  - 如果有人在等球，他就可以拿走刚放进去的球了
  - 放球-拿球的过程实现了同步





## 理解信号量 (3)

扩展的互斥锁：一个手环 → *n* 个手环

- 让更多同学可以进入更衣室
  - 管理员可以持有任意数量的手环 (count, 更衣室容量上限)
  - 先进入更衣室的同学先进入游泳池
  - 手环用完后需要等同学出来
- 信号量对应了 “资源数量”







## 信号量：实现优雅的生产者-消费者

信号量设计的重点

- 考虑 “球”/“手环” (每一单位的 “资源”) 是什么
- 生产者/消费者 = 把球从一个袋子里放到另一个袋子里

```
void Tproduce() {
  P(&empty);
  printf("("); // 注意共享数据结构访问需互斥
  V(&fill);
}
void Tconsume() {
  P(&fill);
  printf(")");
  V(&empty);
}
```





## 信号量的两种典型应用

1. 实现一次临时的 happens-before
   - 初始：s = 0
   - A; V(s)
   - P(s); B
     - 假设 s 只被使用一次，保证 A happens-before B
2. 实现计数型的同步
   - 初始：done = 0
   - Tworker: V(done)
   - Tmain: P(done) ×*T*



------

对应了两种线程 join 的方法

- 1→2→…*T*1→*T*2→… v.s. 完成就行，不管顺序





## 例子：实现计算图

对于任何计算图

- 为每个节点分配一个线程
  - 对每条入边执行 P (wait) 操作
  - 完成计算任务
  - 对每条出边执行 V (post/signal) 操作
    - 每条边恰好 P 一次、V 一次
    - PLCS 直接就解决了啊？

```
void Tworker_d() {
  P(bd); P(ad); P(cd);
  // 完成节点 d 上的计算任务
  V(de);
}
```







## 实现计算图 (cont'd)

乍一看很厉害

- 完美解决了并行问题

------

实际上……

- 创建那么多线程和那么多信号量 = Time Limit Exceeded
- 解决线程太多的问题
  - 一个线程负责多个节点的计算
    - 静态划分 → 覆盖问题
    - 动态调度 → 又变回了生产者-消费者
- 解决信号量太多的问题
  - 计算节点共享信号量
    - 可能出现 “假唤醒” → 又变回了条件变量





## 例子：毫无意义的练习题

有三种线程

- Ta 若干: 死循环打印 `<`
- Tb 若干: 死循环打印 `>`
- Tc 若干: 死循环打印 `_`
- 如何同步这些线程，保证打印出 `<><_` 和 `><>_` 的序列？

------

信号量的困难

- 上一条鱼打印后，`<` 和 `>` 都是可行的
- 我应该 P 哪个信号量？
  - 可以 P 我自己的
  - 由打印 `_` 的线程随机选一个









## 例子：使用信号量实现条件变量

当然是问 AI 了

- ChatGPT (GPT-3.5) 直接一本正经胡说八道
  - 这个对 LLM 还是太困难了
- New Bing 给出了一种 “思路”
  - 第一个 wait 的线程会在持有 mutex 的情况下 P(cond)
  - 从此再也没有人能获得互斥锁……
    - ~~像极了我改期末试卷的体验~~







## 使用信号量实现条件变量：本质困难

操作系统用自旋锁保证 wait 的原子性

```
wait(cv, mutex) {
  release(mutex);
  sleep();
}
```

------

[信号量实现的矛盾](http://birrell.org/andrew/papers/ImplementingCVs.pdf)

- 不能带着锁睡眠 (NewBing 犯的错误)
- 也不能先释放锁
  - `P(mutex); nwait++; V(mutex);`
  - 此时 signal/broadcast 发生，唤醒了后 wait 的线程
  - `P(sleep);`
- (我们稍后介绍解决这种矛盾的方法)





## 信号量的使用：小结

信号量是对 “袋子和球/手环” 的抽象

- 实现一次 happens-before，或是计数型的同步
  - 能够写出优雅的代码
  - `P(empty); printf("("); V(fill)`
- 但并不是所有的同步条件都容易用这个抽象来表达







## 哲学家吃饭问题 (E. W. Dijkstra, 1960)

经典同步问题：哲学家 (线程) 有时思考，有时吃饭

- 吃饭需要同时得到左手和右手的叉子
- 当叉子被其他人占有时，必须等待，如何完成同步？





## 失败与成功的尝试

失败的尝试

- 把信号量当互斥锁：先拿一把叉子，再拿另一把叉子

------

成功的尝试 (万能的方法)

```
#define CAN_EAT (avail[lhs] && avail[rhs])
mutex_lock(&mutex);
while (!CAN_EAT)
  cond_wait(&cv, &mutex);
avail[lhs] = avail[rhs] = false;
mutex_unlock(&mutex);

mutex_lock(&mutex);
avail[lhs] = avail[rhs] = true;
cond_broadcast(&cv);
mutex_unlock(&mutex);
```





## 成功的尝试：信号量

Trick: 死锁会在 5 个哲学家 “同时吃饭” 时发生

- 破坏这个条件即可
  - 保证任何时候至多只有 4 个人可以吃饭
  - 直观理解：大家先从桌上退出
    - 袋子里有 4 张卡
    - 拿到卡的可以上桌吃饭 (拿叉子)
    - 吃完以后把卡归还到袋子
- 任意 4 个人想吃饭，总有一个可以拿起左右手的叉子
  - 教科书上有另一种解决方法 (lock ordering；之后会讲)

------

但这真的对吗？

- [philosopher-check.py](https://jyywiki.cn/pages/OS/2023/c/philosopher-check.py)
- 在必要的时候使用 model checker





## 反思：分布与集中

“Leader/follower” - 有一个集中的 “总控”，而非 “各自协调”

- 在可靠的消息机制上实现任务分派
  - Leader 串行处理所有请求 (例如：条件变量服务)

```
void Tphilosopher(int id) {
  send(Twaiter, id, EAT);
  receive(Twatier); // 等待 waiter 把两把叉子递给哲学家
  eat();
  send(Twaiter, id, DONE); // 归还叉子
}

void Twaiter() {
  while (1) {
    (id, status) = receive(Any);
    switch (status) { ... }
  }
}
```





## 反思：分布与集中 (cont'd)

你可能会觉得，管叉子的人是性能瓶颈

- 一大桌人吃饭，每个人都叫服务员的感觉
- Premature optimization is the root of all evil (D. E. Knuth)



- 吃饭的时间通常远远大于请求服务员的时间
- 如果一个 manager 搞不定，可以分多个 (fast/slow path)
  - 把系统设计好，集中管理可以不是瓶颈：[The Google File System](https://pdos.csail.mit.edu/6.824/papers/gfs.pdf) (SOSP'03) 开启大数据时代







## 经典) 高性能计算

> “A technology that harnesses the power of supercomputers or computer clusters to solve complex problems requiring massive computation.” (IBM)

------

源自数值密集型科学计算任务

- 物理系统模拟
  - 天气预报、航天、制造、能源、制药、……
  - 大到宇宙小到量子，有模型就能模拟
- 矿厂 (现在不那么热了)
  - 纯粹的 hash 计算
- [HPC-China 100](http://www.hpc100.cn/top100/21/)





## 高性能计算程序：特点

物理世界具有 “空间局部性”

- 一切 “模拟物理世界” 的系统都具有 embarrassingly parallel 的特性

交互总是局限在局部，因此可以把模拟分成相近的小块，小块之间会发生作用

只要小块足够多，小块之间的互动就可忽略不计





## 高性能计算：关键问题

问题 1：计算任务如何分解

- 通常计算图容易静态切分 (机器-线程两级任务分解)
- 生产者-消费者解决一切
  - [MPI](https://hpc-tutorials.llnl.gov/mpi/) - “a specification for the developers and users of message passing libraries”, [OpenMP](https://www.openmp.org/) - “multi-platform shared-memory parallel programming in C/C++ and Fortran”
  - [Parallel and Distributed Computation: Numerical Methods](https://web.mit.edu/dimitrib/www/pdc.html)

```
#pragma omp parallel num_threads(128)
for (int i = 0; i < 1024; i++) {
}
```

问题 2：海量线程之间的如何同步和通信

- 持久存储 (~PB) → CPU/内存 (~TB) → GPU/显存 (~10GB) → 缓存 (~MB)





```C
#include "thread.h"
#include <math.h>

int NT;
#define W 6400
#define H 6400
#define IMG_FILE "mandelbrot.ppm"

static inline int belongs(int x, int y, int t) {
  return x / (W / NT) == t;
}

int x[W][H];
_Atomic int done = 0;

void dump(FILE *fp, int step) { 
  int w = W / step, h = H / step;
  // STFW: Portable Pixel Map
  fprintf(fp, "P6\n%d %d 255\n", w, h);
  for (int j = 0; j < H; j += step) {
    for (int i = 0; i < W; i += step) {
      int n = x[i][j];
      int r = 255 * pow((n - 80) / 800.0, 3);
      int g = 255 * pow((n - 80) / 800.0, 0.7);
      int b = 255 * pow((n - 80) / 800.0, 0.5);
      fputc(r, fp); fputc(g, fp); fputc(b, fp);
    }
  }
}

void Tworker(int tid) {
  for (int i = 0; i < W; i++)
    for (int j = 0; j < H; j++)
      if (belongs(i, j, tid - 1)) {
        double a = 0, b = 0, c, d;
        while ((c = a * a) + (d = b * b) < 4 && x[i][j]++ < 880) {
          b = 2 * a * b + j * 1024.0 / H * 8e-9 - 0.645411;
          a = c - d + i * 1024.0 / W * 8e-9 + 0.356888;
        }
      }
  atomic_fetch_add(&done, 1);
}

void Tdump() {
  float ms = 0;
  while (1) {
    FILE *fp = popen("viu -", "w"); assert(fp);
    dump(fp, W / 256);
    pclose(fp);
    if (atomic_load(&done) == NT) break;
    usleep(1000000 / 2);
    ms += 1000.0 / 2;
  }
  printf("Approximate render time: %.1lfs\n", ms / 1000);

  FILE *fp = fopen(IMG_FILE, "w"); assert(fp);
  dump(fp, 2);
  fclose(fp);
}

int main(int argc, char *argv[]) {
  assert(argc == 2);
  NT = atoi(argv[1]);

  create(Tdump);

  #pragma omp parallel num_threads(NT)
  #pragma omp for schedule(static)
  for (int i = 0; i < NT; i++) {
    Tworker(i + 1);  // Sequential code
  }
  // Equivalent to:
  //
  // for (int i = 0; i < NT; i++) {
  //   create(Tworker);
  // }

  join();
  return 0;
}
```



曼德勃罗集 图像绘制







## 数据中心程序：特点

> “A network of computing and storage resources that enable the delivery of *shared* applications and data.” (CISCO)

以数据 (存储) 为中心

- 互联网索引与搜索
  - Google
- 社交网络
  - Facebook/Twitter
- 支撑各类互联网应用
  - 通信 (微信/QQ)、支付 (支付宝)、游戏/网盘/……





## 数据中心：关键问题

如何实现高可靠、低延迟的多副本分布式存储和计算系统？

- 在服务海量地理分布请求的前提下，三者不可兼得：
  - 数据要保持一致 (Consistency)
  - 服务时刻保持可用 (Availability)
  - 容忍机器离线 (Partition tolerance)





## 数据中心程序上的单机程序

事件驱动 + 高并发：系统调用密集且延迟不确定

- 网络数据读写
- 持久存储读写
- 单机程序目标：尽可能多地服务并行的请求
  - QPS: 吞吐量
  - Tail latency: 一个请求慢了，其他请求不能慢

------

假设有数千/数万个请求同时到达服务器……

- 线程能够实现并行处理
- 但远多于处理器数量的线程导致性能问题
  - 切换开销
  - 维护开销







## 协程：操作系统 “不感知” 的上下文切换

和线程概念相同 (独立堆栈、共享内存)

- 但 “一直执行”，直到yield()主动放弃处理器
  - 有编译器辅助，切换开销低
    - yield() 是函数调用，只需保存/恢复 “callee saved” 寄存器
    - 线程切换需要保存/恢复全部寄存器
  - 但等待 I/O 时，其他协程就不能运行了……
    - 失去了并行

------

```
// 只可能是 1122 或 2211
void T1() { send("1"); send("1"); yield(); }
void T2() { send("2"); send("2"); yield(); }
```







## Go 和 Goroutine

> Go: 小孩子才做选择，多处理器并行和轻量级并发我全都要！

Goroutine: 概念上是线程，实际是线程和协程的混合体

- 每个 CPU 上有一个 Go Worker，自由调度 goroutines
- 执行到 blocking API 时 (例如 sleep, read)
  - Go Worker 偷偷改成 non-blocking 的版本
    - 成功 → 立即继续执行
    - 失败 → 立即 yield 到另一个需要 CPU 的 goroutine
      - 太巧妙了！CPU 和操作系统全部用到 100%

------

例子

- Fibonacci number from [*The Go Programming Language* (ch 9.8)](https://books.studygolang.com/gopl-zh/ch9/ch9-08.html)





## Go 语言中的同步

> Do not communicate by sharing memory; instead, share memory by communicating. ——*Effective Go*

共享内存 = 万恶之源

- 信号量/条件变量：实现了同步，但没有实现 “通信”
  - 数据传递完全靠手工 (没上锁就错了)

------

但 UNIX 时代就有一个实现并行的机制了

- ```
  cat *.txt | wc -l
  ```

  - 管道是一个天然的生产者/消费者！
  - 为什么不用 “管道” 实现协程/线程间的同步 + 通信呢？
    - Channels in Go





## 机器学习：既计算密集，又数据密集

GPT-3: [Language models are few-shot learners](https://arxiv.org/abs/2005.14165)

- Transformer 架构
  - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- 175B 参数 (~300GB VRAM, FP-16)
  - GPT-3 single training run cost: ~$5,000,000
  - 美国人断供芯片 = 三体人行为
- 320TB 语料
  - 相比图片和视频，还是小弟弟





注意力机制





## 并行化：Dependency Graph is All You Need

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230803192626.png)







## 计算密集部分 (1)：SIMT

Single Instruction, Multiple Threads

- 一个 PC，控制 32 个执行流同时执行
  - 逻辑线程可以更多
- 执行流有独立的寄存器
  - *x*,*y*,*z* 三个寄存器用于标记 “线程号”，决定线程执行的动作



![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230805003615.png)



![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230805004822.png)

单条指令就能计算很多值





这种结构有一个很致命的问题：遇到分支，计算的时长是两个分支的和，反而比每个核一个pc架构的并行取最大时长来得更慢



## 计算密集部分 (2)：SIMD

Single Instruction, Multiple Data

- Tensor 指令 (Tensor Core)：混合精度

   

  *A*×*B*+*C*

  - 单条指令完成 4×4×4 个乘法运算

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230805005040.png)

## 计算密集部分 (3)：堆更多的处理单元！

GH100 Spec

- 144 SMs
- 18432 CUDA Cores (并行的 Threads)
  - AVX512: 512bits = 16 x Float32
- 576 Tensor Cores (4 per SM)
- 6 HBM3 or HBM2e stacks
- 12 512-bit memory controllers
- 60 MB L2 cache

------

这只是一个 GPU

- 显存/缓存决定了 GPU 内堆处理器的上限
- 但我们可以有多台机器、每个机器有多台 GPU！





## 分布式机器学习

高性能计算 (GPU) + 数据中心计算

- [Scaling distributed machine learning with the parameter server](https://www.usenix.org/conference/osdi14/technical-sessions/presentation/li_mu) (OSDI'14)

![](https://picfloor-1310641479.cos-website.ap-shanghai.myqcloud.com/picfloor/20230805013141.png)





```
#include <stdio.h>
#include <stdint.h>

#define MAX_ITER 100
#define DIM 12800
static uint32_t colors[MAX_ITER + 1];
static uint32_t data[DIM * DIM];

__device__ uint32_t mandelbrot(double x, double y) {
  double zr = 0, zi = 0, zrsqr = 0, zisqr = 0;
  int i;

  for (i = 0; i < MAX_ITER; i++) {
    zi = zr * zi * 2 + y;
    zr = zrsqr - zisqr + x;
    zrsqr = zr * zr;
    zisqr = zi * zi;
    if (zrsqr + zisqr > 4.0) {
      break; // SIMT threads diverges here!
    }
  }
  
  return i;
}

__global__ void mandelbrot_kernel(uint32_t *data, double xmin, double ymin, double step, uint32_t *colors) {
  int pix_per_thread = DIM * DIM / (gridDim.x * blockDim.x);
  int tId = blockDim.x * blockIdx.x + threadIdx.x;
  int offset = pix_per_thread * tId;
  for (int i = offset; i < offset + pix_per_thread; i++) {
    int x = i % DIM;
    int y = i / DIM;
    double cr = xmin + x * step;
    double ci = ymin + y * step;
    data[y * DIM + x] = colors[mandelbrot(cr, ci)];
  }
  if (gridDim.x * blockDim.x * pix_per_thread < DIM * DIM
      && tId < (DIM * DIM) - (blockDim.x * gridDim.x)) {
    int i = blockDim.x * gridDim.x * pix_per_thread + tId;
    int x = i % DIM;
    int y = i / DIM;
    double cr = xmin + x * step;
    double ci = ymin + y * step;
    data[y * DIM + x] = colors[mandelbrot(cr, ci)];
  }
}

int main() {
  float freq = 6.3 / MAX_ITER;
  for (int i = 0; i < MAX_ITER; i++) {
    char r = sin(freq * i + 3) * 127 + 128;
    char g = sin(freq * i + 5) * 127 + 128;
    char b = sin(freq * i + 1) * 127 + 128;
    colors[i] = b + 256 * g + 256 * 256 * r;
  }
  colors[MAX_ITER] = 0;

  uint32_t *dev_colors, *dev_data;
  cudaMalloc((void**)&dev_colors, sizeof(colors));
  cudaMalloc(&dev_data, sizeof(data));
  cudaMemcpy(dev_colors, colors, sizeof(colors), cudaMemcpyHostToDevice);

  double xcen = -0.5, ycen = 0, scale = 3;
  mandelbrot_kernel<<<512, 512>>>(
    dev_data,
    xcen - (scale / 2),
    ycen - (scale / 2),
    scale / DIM,
    dev_colors
  );

  cudaMemcpy(data, dev_data, sizeof(data), cudaMemcpyDeviceToHost);
  cudaFree(dev_data);
  cudaFree(dev_colors);

  FILE *fp = fopen("mandelbrot.ppm", "w");
  fprintf(fp, "P6\n%d %d 255\n", DIM, DIM);
  for (int i = 0; i < DIM * DIM; i++) {
    fputc((data[i] >> 16) & 0xff, fp);
    fputc((data[i] >>  8) & 0xff, fp);
    fputc((data[i] >>  0) & 0xff, fp);
  }
  
  return 0;
}
```

> GPU 的编程模型和 CPU 略有不同。我们需要指定在 GPU 上运行的代码 (用 `__device__` 和 `__global__` 标记)，并使用 cudaMemcpy 完成显存和内存时间的数据传递。我们还可以用 cuobjdump 查看编译到 GPU 上的汇编指令。









## Web 2.0 时代 (1999)

人与人之间联系更加紧密的互联网

- “Users were encouraged to provide content, rather than just viewing it.”
- 你甚至可以找到一些 “Web 3.0”/Metaverse 的线索

------

是什么成就了今天的 Web 2.0?

- HTML (DOM Tree) + CSS = 终端世界
  - 通过 JavaScript 可以改变它
  - 通过 JavaScript 可以连接数据中心
  - Ajax (Asynchronous JavaScript + XML) 和 `$`
- 例子：Jupyter Notebook





## 人机交互程序：特点和主要挑战

特点：不太复杂

- 既没有太多计算
  - DOM Tree 也不至于太大 (大了人也看不过来)
  - DOM Tree 怎么画浏览器全帮我们搞定了
- 也没有太多 I/O
  - 就是一些网络请求

------

挑战：程序员多

- 零基础的人你让他整共享内存上的多线程
- 恐怕我们现在用的到处都是 bug 吧？？？
  - 框架：不用怕，有我在
  - AI: 不用怕，有我在







## 单线程 + 事件模型

尽可能少但又足够的并发

- 一个线程、全局的事件队列、按序执行 (run-to-complete)
- 耗时的 API (Timer, Ajax, ...) 调用会立即返回
  - 条件满足时向队列里增加一个事件

```
$.ajax(
  {
    url: 'https://jyywiki.cn/hello/jyy',
    success: function(resp) {
      console.log(resp);
    },
    error: function(req, status, err) {
      console.log("Error");
    }
  }
);
```







## 异步事件模型

好处

- 并发模型简单了很多
  - 函数的执行是原子的 (不能并行，减少了并发 bug 的可能性)
- API 依然可以并行
  - 适合网页这种 “大部分时间花在渲染和网络请求” 的场景
    - JavaScript 代码只负责 “描述” DOM Tree

------

坏处

- Callback hell (祖传屎山)
  - `$.ajax` 嵌套 5 层，可维护性已经接近于零了







## 异步编程：Promise

> 导致 callback hell 的本质：人类脑袋里想的是 “流程图”，看到的是 “回调”。

The Promise object represents the *eventual completion* (or failure) of an asynchronous operation and its resulting value.









## Promise: 描述 Workflow 的 “嵌入式语言”

Chaining

```
loadScript("/article/promise-chaining/one.js")
  .then( script => loadScript("/article/promise-chaining/two.js") )
  .then( script => loadScript("/article/promise-chaining/three.js") )
  .then( script => {
    // scripts are loaded, we can use functions declared there
  })
  .catch(err => { ... } );
```

------

Fork-join

```
a = new Promise( (resolve, reject) => { resolve('A') } )
b = new Promise( (resolve, reject) => { resolve('B') } )
c = new Promise( (resolve, reject) => { resolve('C') } )
Promise.all([a, b, c]).then( res => { console.log(res) } )
```







## Async-Await: 一种计算图的描述语言

async function

- 总是返回一个 `Promise` object
- `async_func()` - fork

------

await promise

- `await promise` - join

------

```
A = async () => await $.ajax('/hello/a')
B = async () => await $.ajax('/hello/b')
C = async () => await $.ajax('/hello/c')
hello = async () => await Promise.all([A(), B(), C()])
hello()
  .then(window.alert)
  .catch(res => { console.log('fetch failed!') } )
```
